{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PATHS- set for multiple computers, see bottom to SET PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASO lidar - netCDFs & integers in [mm]\n",
    "ars_path = '/home/meganmason/Documents/projects/thesis/data/processing_lidar/depths_3m/equal_extent_data_downsize/nc/20*/*int.nc'\n",
    "bsu_path = '/Users/meganmason491/Documents/research/sierra/data/mm/20*/*int.nc'\n",
    "sonic_path = '/home/meganmason/Research/Sierra/data/mm/20*/*int.nc'\n",
    "\n",
    "#DEM & Mask for Tuolumne (topo.nc @ 3m cell size) - dem here is from national database...(10m>3m)\n",
    "ars_topo_path = '/home/meganmason/Documents/projects/thesis/maps/map_layers/basin_ops/tuolumne/topo/basin_setup_3m/topo.nc'\n",
    "bsu_topo_path = '/Users/meganmason491/Documents/research/sierra/data/topo.nc'\n",
    "sonic_topo_path = '/home/meganmason/Research/Sierra/data/topo.nc'\n",
    "\n",
    "# ASO snow-free and surface class\n",
    "ars_terrain_path = '/home/meganmason/Documents/projects/thesis/data/processing_lidar/depths_3m/equal_extent/*.nc'\n",
    "bsu_terrain_path = '/Users/meganmason491/Documents/research/sierra/data/terrain/*.nc'\n",
    "# sonic_terrain_path = ''\n",
    "\n",
    "\n",
    "# ~~ SET PATH HERE ~~ #\n",
    "path = bsu_path\n",
    "topo_path = bsu_topo_path\n",
    "terrain_path = bsu_terrain_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FILEPATH LIST AND DATE PARSING (lidar only here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of lidar files as input: 51\n",
      "dates, file type is: <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n"
     ]
    }
   ],
   "source": [
    "# filepath list, lidar\n",
    "flist = sorted(glob.glob(path))\n",
    "print('# of lidar files as input:', len(flist))\n",
    "\n",
    "# Parse dates, store as pandas datetime type in list\n",
    "fparse = [d.split('/')[-1] for d in flist] #splits fname on '/' saves last\n",
    "fparse = [d.split('_')[0] for d in fparse] #splits fname on '_' saves first\n",
    "\n",
    "# flight dates, parsed from filename\n",
    "dates = pd.to_datetime(fparse) #pandas datetime variable, lidar dates\n",
    "print('dates, file type is:', type(dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTION: run a smaller chunk, peak, etc.\n",
    "Activate if you want to run 2 flights, peak flights, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''first 2 files'''\n",
    "# # flist = flist[:2] #first 6 are just 2013\n",
    "# # dates = dates[:2]\n",
    "\n",
    "# '''peak snow depth dates....(?)'''\n",
    "# flist = list(flist[i] for i in (0,7,22,28,41,49))\n",
    "# dates = list(dates[i] for i in (0,7,22,28,41,49))\n",
    "\n",
    "# print('# of lidar files as input:', len(flist))\n",
    "# print('# of flight dates', len(dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUILD XARRAY DATASET\n",
    "* open multiple files (mf) from file list (lidar res = 3m)\n",
    "* name the concatinating dimention, 'time'\n",
    "* 'nested' vs 'comb_by_cords' .....not totally clear, but no error!\n",
    "* set chunk size (prefered is 1 million in size (1000x1000)\n",
    "* activate DASK with parallel\n",
    "* rename data to 'snow' on the fly\n",
    "* drop a variable\n",
    "* close to remove from memory\n",
    "\n",
    "#### ADD 'TIME' COORDINATE \n",
    "\n",
    "* time coord from file name dates, by default populates with 'time' dimension\n",
    "\n",
    "#### FLIP 'Y' COORD (corrects orientation for imshow() ) \n",
    "* flips horizonally (but actually flips 'Y')\n",
    "    *NOTE: tried several options flipud, flip w/ axis=0, etc. \n",
    "* flip causes DataSet to become a DataArray, set back to DataSet\n",
    "    *NOTE: changes set chunk size, solution - set chunk size when compiled netCDF is loaded in analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 51, x: 17569, y: 17002)\n",
       "Coordinates:\n",
       "  * y        (y) float64 4.23e+06 4.23e+06 4.23e+06 ... 4.179e+06 4.179e+06\n",
       "  * x        (x) float64 2.54e+05 2.54e+05 2.54e+05 ... 3.067e+05 3.067e+05\n",
       "  * time     (time) datetime64[ns] 2013-04-03 2013-04-29 ... 2018-05-28\n",
       "Data variables:\n",
       "    snow     (time, y, x) float32 dask.array<chunksize=(1, 2, 1000), meta=np.ndarray>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build xarray\n",
    "ds=xr.open_mfdataset(flist, \n",
    "                     concat_dim='time', \n",
    "                     combine='nested',\n",
    "                     chunks={'x':1000, 'y':1000}, \n",
    "                     parallel=True).rename({'Band1':'snow'}).drop('transverse_mercator') #combine='nested', \n",
    "\n",
    "ds.close()\n",
    "\n",
    "# add 'time' coord\n",
    "ds['time'] = (['time'], dates) \n",
    "\n",
    "# flip 'y' up/down\n",
    "ds=np.flip(ds.snow,1) \n",
    "ds=ds.to_dataset()\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open topo.nc (dem, mask, veg_height)\n",
    "Cell size is 3m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topo = xr.open_dataset(topo_path)#, drop_variables=['veg_tau','veg_k','veg_type','projection'], chunks={'x':1000, 'y':1000})\n",
    "topo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1). assign mask to ds coords\n",
    "ds = ds.assign_coords(mask=topo.mask)\n",
    "\n",
    "# 2). assign 'dem' and 'veg' as coords where mask==1 \n",
    "ds = ds.assign_coords(dem=topo.dem.where(ds.mask==1))\n",
    "ds = ds.assign_coords(veg=topo.veg_height.where(ds.mask==1))\n",
    "\n",
    "# 3). mask the watershed (snow is only variable in ds)\n",
    "ds=ds.where(ds.mask==1)\n",
    "\n",
    "# 4). change dtypes of snow depth before saving output\n",
    "ds=ds.astype(np.int16, copy=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate topo layers with lidar DataSet (ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add topo features to lidar DataSet (ds) as DATA_VARS\n",
    "# ds['mask'] = (['y','x'],topo.mask) \n",
    "# ds['dem'] = (['y','x'],topo.dem)\n",
    "# ds['veg'] = (['y','x'],topo.veg_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHOW THAT MASK IS APPLIED TO DATASET\n",
    "~ Do some subplots here to show this nicer.... ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ds.snow[0]/1000, cmap='coolwarm'); plt.colorbar(); plt.title('One snow depth image'); plt.show() #zeros outside of mask because nans=float, 0=ints\n",
    "plt.imshow(ds.dem, cmap='terrain'); plt.colorbar(); plt.title('DEM'); plt.show()\n",
    "plt.imshow(ds.veg, cmap='Greens'); plt.colorbar(); plt.title('Veg Height'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(ds.snow[0]/1000, cmap='coolwarm'); plt.colorbar(); plt.title('One snow depth image'); plt.show() #zeros outside of mask because nans=float, 0=ints\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "plt.imshow(ds.dem, cmap='terrain'); plt.title('DEM'); plt.axis('off')\n",
    "plt.savefig('../figs/dem_for_graphic', dpi=300, transparent=True)\n",
    "\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "plt.imshow(ds.veg, cmap='summer'); plt.title('Veg Height'); plt.axis('off')\n",
    "plt.savefig('../figs/vegHeight_for_graphic', dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVE OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 51, x: 17569, y: 17002)\n",
       "Coordinates:\n",
       "  * y        (y) float32 4230327.0 4230324.0 4230321.0 ... 4179327.0 4179324.0\n",
       "  * x        (x) float32 254007.0 254010.0 254013.0 ... 306708.0 306711.0\n",
       "  * time     (time) datetime64[ns] 2013-04-03 2013-04-29 ... 2018-05-28\n",
       "    mask     (y, x) uint8 0 0 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "    dem      (y, x) float32 nan nan nan nan nan nan ... nan nan nan nan nan nan\n",
       "    veg      (y, x) float32 nan nan nan nan nan nan ... nan nan nan nan nan nan\n",
       "Data variables:\n",
       "    snow     (time, y, x) int16 dask.array<chunksize=(1, 2, 1000), meta=np.ndarray>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment when you want to save:\n",
    "# ds.to_netcdf('~/Documents/projects/thesis/results/output/compiled_SUPERsnow.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
