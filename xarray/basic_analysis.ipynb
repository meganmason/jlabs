{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.15674201"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = '~/Documents/projects/thesis/results/output/compiled_SUPERsnow.nc'\n",
    "\n",
    "ds = xr.open_dataset(fname,  chunks={'time':1,'x':1000,'y':1000})\n",
    "ds.close()\n",
    "ds.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 6, x: 17569, y: 17002)\n",
       "Coordinates:\n",
       "  * x        (x) float32 254007.0 254010.0 254013.0 ... 306708.0 306711.0\n",
       "  * y        (y) float32 4230327.0 4230324.0 4230321.0 ... 4179327.0 4179324.0\n",
       "  * time     (time) datetime64[ns] 2013-04-03 2013-04-29 ... 2013-06-08\n",
       "    mask     (y, x) uint8 dask.array<shape=(17002, 17569), chunksize=(1000, 1000)>\n",
       "    dem      (y, x) float32 dask.array<shape=(17002, 17569), chunksize=(1000, 1000)>\n",
       "    veg      (y, x) float32 dask.array<shape=(17002, 17569), chunksize=(1000, 1000)>\n",
       "Data variables:\n",
       "    snow     (time, y, x) int16 dask.array<shape=(6, 17002, 17569), chunksize=(1, 1000, 1000)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select peak snow dates\n",
    "dsmall = ds.sel(time='2013')\n",
    "dsmall.close()\n",
    "\n",
    "ds = dsmall\n",
    "ds.close()\n",
    "ds\n",
    "\n",
    "# '''peak snow depth dates....(?)'''\n",
    "# flist = list(flist[i] for i in (0,7,22,28,41,49))\n",
    "# dates = list(dates[i] for i in (0,7,22,28,41,49))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(ds.snow[0]/1000, cmap='coolwarm'); plt.colorbar(); plt.title('One snow depth image'); plt.show() #zeros outside of mask because nans=float, 0=ints\n",
    "# plt.imshow(ds.dem, cmap='terrain'); plt.colorbar(); plt.title('DEM'); plt.show()\n",
    "# plt.imshow(ds.veg, cmap='Greens'); plt.colorbar(); plt.title('Veg Height'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#std over 2013\n",
    "std=ds.snow.std(dim='time')\n",
    "std = np.where(std>.001, std, np.nan)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "plt.imshow(std/1000, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.title('Standard deviation [m] snow depth 2013 (6 flights)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sd above treeline\n",
    "\n",
    "# d = ds.snow.where(ds.snow>0)\n",
    "# print(d)\n",
    "sd_above_treeline = ds.snow.where(ds.dem > 2900)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "plt.imshow(sd_above_treeline[3], cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.title('Snow Depth [mm] above 2900m one time 2013')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_above_treeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standardize snow depth function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MM working\n",
    "\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#  standardize lidar\n",
    "\n",
    "def standard(x):\n",
    "    a = np.where(x>0, x, np.nan)\n",
    "    return x/np.nanmean(a)\n",
    "\n",
    "s = xr.apply_ufunc(standard, ds.snow, dask='parallelized', output_dtypes=[np.int16])\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#  compute normalized stand dev for peak SWE dates\n",
    "s_std=np.nanstd(s,axis=0) #np language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "plt.imshow(np.where(s_std>0,s_std,np.nan),cmap='jet', vmax=1)\n",
    "plt.colorbar()\n",
    "plt.title('Standard deviation snow depth 2013 (6 flights)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### histogram attempt with np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 6, x: 17569, y: 17002)\n",
       "Coordinates:\n",
       "  * x        (x) float32 254007.0 254010.0 254013.0 ... 306708.0 306711.0\n",
       "  * y        (y) float32 4230327.0 4230324.0 4230321.0 ... 4179327.0 4179324.0\n",
       "  * time     (time) datetime64[ns] 2013-04-03 2013-04-29 ... 2013-06-08\n",
       "    mask     (y, x) uint8 dask.array<shape=(17002, 17569), chunksize=(1000, 1000)>\n",
       "    dem      (y, x) float32 dask.array<shape=(17002, 17569), chunksize=(1000, 1000)>\n",
       "    veg      (y, x) float32 dask.array<shape=(17002, 17569), chunksize=(1000, 1000)>\n",
       "Data variables:\n",
       "    snow     (time, y, x) int16 dask.array<shape=(6, 17002, 17569), chunksize=(1, 1000, 1000)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.nbytes / 1e9\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram function\n",
    "def histogram(x):\n",
    "    a = np.where(x>0, x, np.nan)\n",
    "    return np.histogram(a, bins=50)\n",
    "\n",
    "s = xr.apply_ufunc(histogram, ds.isel(time=1).snow, dask='parallelized', output_dtypes=[np.int16] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'snow' (y: 17002, x: 17569)>\n",
       "dask.array<shape=(17002, 17569), dtype=int16, chunksize=(1000, 1000)>\n",
       "Coordinates:\n",
       "  * x        (x) float32 254007.0 254010.0 254013.0 ... 306708.0 306711.0\n",
       "  * y        (y) float32 4230327.0 4230324.0 4230321.0 ... 4179327.0 4179324.0\n",
       "    time     datetime64[ns] 2013-04-29\n",
       "    mask     (y, x) uint8 dask.array<shape=(17002, 17569), chunksize=(1000, 1000)>\n",
       "    dem      (y, x) float32 dask.array<shape=(17002, 17569), chunksize=(1000, 1000)>\n",
       "    veg      (y, x) float32 dask.array<shape=(17002, 17569), chunksize=(1000, 1000)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MM with Charlie\n",
    "\n",
    "# # Normalized variance for flights closest to peak SWE dates\n",
    "# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# # 1). mean snow depth for each year (get 6 means for each year, 2013-2018 (compute without zeros ideally))\n",
    "# # means=ds.snow.mean(dim=('x', 'y')) #ds.mean(dim=('x','y')--mean over all layers)\n",
    "# # means\n",
    "\n",
    "# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# # 2). standardize lidar\n",
    "\n",
    "# def standard(x):\n",
    "#     a = np.where(x>0, x, np.nan)\n",
    "#     return x/np.nanmean(a)\n",
    "\n",
    "# s = xr.apply_ufunc(standard, ds.snow)\n",
    "\n",
    "# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# # 3). compute normalized variance for peak SWE dates\n",
    "# s_var=np.nanvar(s,axis=0) #np language"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
