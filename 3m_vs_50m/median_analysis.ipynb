{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis to investigate the median snow depth for ASO lidar data between 3m and 50m product\n",
    "* 3m data: compiled netCDFwith 3m topo.nc \n",
    "    * units = mm\n",
    "    * mask: applied (in compiling step)\n",
    "* 50m data: ascii files with 50m hetch mask\n",
    "    * units = m\n",
    "    * mask: APPLY HERE!\n",
    "\n",
    "NOTE: masks do not pefectly line up, not ideal, but for size of dataset this should still produce useful initial results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from scipy.stats import pearsonr \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "# import dask.array as da\n",
    "# from dask.diagnostics import ProgressBar\n",
    "# from dask.distributed import Client, LocalCluster\n",
    "\n",
    "import matplotlib.patheffects as PathEffects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load 3m data (xarray: compiled netCDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 51, x: 17569, y: 17002)\n",
       "Coordinates:\n",
       "  * x        (x) float32 254007.0 254010.0 254013.0 ... 306708.0 306711.0\n",
       "  * y        (y) float32 4230327.0 4230324.0 4230321.0 ... 4179327.0 4179324.0\n",
       "  * time     (time) datetime64[ns] 2013-04-03 2013-04-29 ... 2018-05-28\n",
       "    mask     (y, x) uint8 dask.array<chunksize=(1000, 1000), meta=np.ndarray>\n",
       "    dem      (y, x) float32 dask.array<chunksize=(1000, 1000), meta=np.ndarray>\n",
       "    veg      (y, x) float32 dask.array<chunksize=(1000, 1000), meta=np.ndarray>\n",
       "Data variables:\n",
       "    snow     (time, y, x) int16 dask.array<chunksize=(1, 1000, 1000), meta=np.ndarray>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fname = '~/Documents/projects/thesis/results/output/compiled_SUPERsnow.nc' #ARS\n",
    "fname = '~/Documents/research/sierra/data/compiled_SUPERsnow.nc' #BSU\n",
    "\n",
    "years = range(2013,2017) #2013-2017\n",
    "\n",
    "#~~~~ ds full\n",
    "ds = xr.open_dataset(fname,  chunks={'time':1,'x':1000,'y':1000})\n",
    "ds.close \n",
    "ds\n",
    "\n",
    "#~~~~~~~~~~~~~~ds subset\n",
    "# dsubset = ds.sel(time=slice('2013','2017'))\n",
    "# dsubset.close()\n",
    "\n",
    "# ds = dsubset\n",
    "# ds.close()\n",
    "# ds\n",
    "\n",
    "# dsmall = ds.sel(time='2018')\n",
    "# dsmall.close()\n",
    "\n",
    "# ds = dsmall\n",
    "# ds.close()\n",
    "# ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/data_analysis/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: dropping dimensions using list-like labels is deprecated; use dict-like arguments.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 49, x: 17569, y: 17002)\n",
       "Coordinates:\n",
       "  * x        (x) float32 254007.0 254010.0 254013.0 ... 306708.0 306711.0\n",
       "  * y        (y) float32 4230327.0 4230324.0 4230321.0 ... 4179327.0 4179324.0\n",
       "  * time     (time) datetime64[ns] 2013-04-03 2013-04-29 ... 2018-05-28\n",
       "    mask     (y, x) uint8 dask.array<chunksize=(1000, 1000), meta=np.ndarray>\n",
       "    dem      (y, x) float32 dask.array<chunksize=(1000, 1000), meta=np.ndarray>\n",
       "    veg      (y, x) float32 dask.array<chunksize=(1000, 1000), meta=np.ndarray>\n",
       "Data variables:\n",
       "    snow     (time, y, x) int16 dask.array<chunksize=(1, 1000, 1000), meta=np.ndarray>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop 4/1/2016  & 7-27-2019 (tmp because 50m version needs extent fixing....)\n",
    "#dlist = map(np.datetime64, ['2016-04-01', '2017-07-27'])  #function, [list of things]\n",
    "ds = ds.drop([np.datetime64('2016-04-01'), np.datetime64('2017-07-27') ], dim='time')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataframes 3m\n",
    "compute median for 3m data and store in pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "median is not yet implemented on dask arrays",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m//anaconda3/envs/data_analysis/lib/python3.6/site-packages/xarray/core/duck_array_ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                     \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdask_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'dask.array' has no attribute 'median'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m//anaconda3/envs/data_analysis/lib/python3.6/site-packages/xarray/core/duck_array_ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/data_analysis/lib/python3.6/site-packages/xarray/core/duck_array_ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: requires dask >=%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_dask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'dask.array' has no attribute 'median': requires dask >=None",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6403a000eb23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 3m median\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmedians_3m\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmedians_3m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmedians_3m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#m3 medians gt 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/data_analysis/lib/python3.6/site-packages/xarray/core/common.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(self, dim, axis, skipna, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 return self.reduce(\n\u001b[0;32m---> 47\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_lazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 )\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/data_analysis/lib/python3.6/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, func, dim, axis, keep_attrs, keepdims, **kwargs)\u001b[0m\n\u001b[1;32m   2129\u001b[0m         \"\"\"\n\u001b[1;32m   2130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2131\u001b[0;31m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_attrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace_maybe_drop_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/data_analysis/lib/python3.6/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, func, dim, axis, keep_attrs, keepdims, allow_lazy, **kwargs)\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_lazy\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/data_analysis/lib/python3.6/site-packages/xarray/core/duck_array_ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m                     \u001b[0;34m\"or newer to use skipna=True or skipna=None\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: median is not yet implemented on dask arrays"
     ]
    }
   ],
   "source": [
    "# 3m median\n",
    "medians_3m=ds.snow.median(dim=('x', 'y'))\n",
    "medians_3m = medians_3m.values/10\n",
    "\n",
    "#m3 medians gt 0\n",
    "medians_3m_gt0 = ds.snow.where(ds.snow > 0).median(dim=('x','y'))\n",
    "medians_3m_gt0 = medians_3m_gt0.values/10\n",
    "\n",
    "# three_m_df = pd.DataFrame(zip(medians_3m, medians_3m_gt0), columns = ['3m (cm)','3m>0 (cm)'], index = ds.time.dt.strftime('%Y-%m-%d'))\n",
    "# three_m_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load 50m data (ascii files: downloaded from AH's published dataset on zenodo and ARS snow server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_50m_years = list(range(2013,2018))\n",
    "\n",
    "# #~~~ARS\n",
    "# mask and DEM\n",
    "# mask_50m_path = '/home/meganmason/Documents/projects/thesis/data/processing_lidar/depths_50m/tuolx_hetchy_mask_50m.asc'\n",
    "# dem_50m_path = '/home/meganmason/Documents/projects/thesis/data/processing_lidar/depths_50m/tuolx_dem_50m.asc'\n",
    "\n",
    "# # ASO snow depth surfaces\n",
    "# depth_50m_path = '/home/meganmason/Documents/projects/thesis/data/processing_lidar/depths_50m/ASO_50m_depth_surfaces/asc/*.asc'\n",
    "\n",
    "#~~~BSU\n",
    "base_path = '/Users/meganmason491/Documents/research/sierra/data/50m_analysis/'\n",
    "\n",
    "# mask and DEM\n",
    "mask_50m_path = base_path + 'tuolx_hetchy_mask_50m.asc'\n",
    "dem_50m_path = base_path + 'tuolx_dem_50m.asc'\n",
    "\n",
    "# ASO snow depth surfaces\n",
    "depth_50m_path = base_path + 'asc/*.asc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask and DEM\n",
    "mask_50m = np.loadtxt(mask_50m_path, skiprows=6)\n",
    "dem_50m = np.loadtxt(dem_50m_path, skiprows=6)\n",
    "\n",
    "#ASo snow depth surfaces \n",
    "flist = glob.glob(depth_50m_path)\n",
    "flist = sorted(flist)\n",
    "print('Number of files as input:', len(flist))\n",
    "\n",
    "flight_dates = []\n",
    "\n",
    "for f in sorted(flist):\n",
    "    dt_str = f.split(\"/\")[-1] #splits on '/' and saves the last one\n",
    "    dt_str = \"\".join([c for c in dt_str if c.isnumeric()]) #grabs numeric values for date info\n",
    "    flight_dates.append(dt_str) #append to flight_date list\n",
    "\n",
    "# flight_dates # flight dates as strings\n",
    "\n",
    "flight_dates_dt = [datetime.strptime(flight_date, '%Y%m%d') for flight_date in flight_dates]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataframes 50m \n",
    "compute medians for 50m data and store in pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_snow_depth(depth_array, convert_factor = 1e-3, mask_array = None, mask_value = None):\n",
    "    '''\n",
    "    Gets median snow depth for ASO snow depth surfaces\n",
    "        args:\n",
    "            depth_array: numpy array from asc files\n",
    "            dx: cellsize [m] in x direction\n",
    "            dy: cellsize [m] in y direction\n",
    "            convert_factor: (optional, default is 0.001 from mm to m)\n",
    "            mask_array: (Optional) mask of the area for depth calculation\n",
    "                       If no mask is provided will calculate for entire array\n",
    "            mask_value: (Optional) value of the mask to calculate over\n",
    "                       Default value will be any positive integer\n",
    "           Note: depth_array and mask_array should cover the same extent \n",
    "                 and have the same dx,dy\n",
    "       return:\n",
    "           median_depth: median depth [m] over the area in mask\n",
    "                       or the full area in the array if no mask is provided\n",
    "    '''\n",
    "    \n",
    "    if mask_array is None:\n",
    "        pass\n",
    "\n",
    "        \n",
    "    else:\n",
    "        median_depth = np.nanmedian(depth_array[[(mask_array == mask_value) & (depth_array >= 0)]] * convert_factor)\n",
    "        median_depth_gt0 = np.nanmedian(depth_array[[(mask_array == mask_value) & (depth_array > 0)]] * convert_factor)\n",
    "#         sca = (depth_array[[(mask_array == mask_value) & (depth_array > 0)]].size / mask_array[mask_array == mask_value].size) * 100\n",
    "        \n",
    "    return median_depth, median_depth_gt0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians_50m = []\n",
    "medians_50m_gt0 = []\n",
    "\n",
    "for f in sorted(flist):\n",
    "    \n",
    "    depth_array = np.loadtxt(f, skiprows=6) #load asc files\n",
    "    median_depth, median_depth_gt0 = median_snow_depth(depth_array, convert_factor=100, mask_array=mask_50m, mask_value=np.max(mask_50m)) #call median_snow_depth function\n",
    "    \n",
    "    medians_50m.append(median_depth)\n",
    "    medians_50m_gt0.append(median_depth_gt0)\n",
    "\n",
    "    \n",
    "# fifty_m_df = pd.DataFrame(zip(medians_50m, medians_50m_gt0), columns = ['50m (cm)','50m>0 (cm)'], index = ds.time.dt.strftime('%Y-%m-%d'))\n",
    "# fifty_m_df\n",
    "# NOTE, index equals xarray 3m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zip up dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(zip(medians_3m_gt0.values/10, medians_50m_gt0, medians_3m.values/10, medians_50m, flight_dates_dt), \n",
    "#                   columns = ['3m>0 (cm)', '50m>0 (cm)', '3m (cm)','50m (cm)', 'flight_dates (50m)'], \n",
    "#                   index = ds.time.dt.strftime('%Y-%m-%d'))\n",
    "# df\n",
    "\n",
    "df = pd.DataFrame(zip(medians_3m_gt0, medians_50m_gt0, medians_3m, medians_50m), \n",
    "                  columns = ['3m>0 (cm)', '50m>0 (cm)', '3m (cm)','50m (cm)']) #, \n",
    "#                   index = flight_dates_dt)\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "\n",
    "# plt.plot_date(df['flight_dates (50m)'], df.columns[:-1], fmt='x', tz=None, xdate=True, ydate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
