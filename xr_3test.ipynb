{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meganmason/Documents/projects/thesis/analysis/virtual_envs/data_analysis/lib/python3.6/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/home/meganmason/Documents/projects/thesis/analysis/virtual_envs/data_analysis/lib/python3.6/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied do not have global dimension coordinates. In\n",
      "future, to continue concatenating without supplying dimension\n",
      "coordinates, please use the new `combine_nested` function (or the\n",
      "`combine='nested'` option to open_mfdataset.\n",
      "  coords=coords)\n"
     ]
    }
   ],
   "source": [
    "path = '/home/meganmason/Documents/projects/thesis/data/processing_lidar/depths_3m/equal_extent_data_downsize/nc/2013/*.nc'\n",
    "flist = glob.glob(path)\n",
    "\n",
    "ds=xr.open_mfdataset(flist, concat_dim='time')\n",
    "ds.close()\n",
    "\n",
    "# ds.chunks #chunks along each dimention (chunks should be 1 million elements max)\n",
    "# d = ds.std(dim='time')\n",
    "# d_flat = d.flatten()\n",
    "\n",
    "# sig = ds.Band1.std(dim='time').chunks\n",
    "# sig = np.where(sig>.001, sig, np.nan)\n",
    "# print(sig)\n",
    "# print('done')\n",
    "\n",
    "#dask/chunks/process bar: https://geohackweek.github.io/nDarrays/08-out-of-core-computation/\n",
    "# from dask.diagnostics import ProgressBar\n",
    "# with ProgressBar():\n",
    "#   ds.sst.groupby('time.year').mean().plot()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sig.shape)\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.imshow(sig[::-1,:], cmap='jet', vmin=.05, vmax=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=ds['Band1']\n",
    "\n",
    "h = np.histogram(d[~np.isnan()].values)\n",
    "\n",
    "# hist = np.histogram(d[~np.isnan(d)].values.flatten(), bins=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_flat = sig.flatten()\n",
    "print(type(sig_flat))\n",
    "plt.plot(sig_flat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for one\n",
    "path = '/home/meganmason/Documents/projects/thesis/data/processing_lidar/depths_3m/all/nc/20140323_SUPERsnow_depth_3mCl.nc'\n",
    "\n",
    "ds = xr.open_dataset(path)\n",
    "\n",
    "f=path\n",
    "dt_str = f.split(\"/\")[-1] #splits on / and saves the last one\n",
    "dt_str = \"\".join([c for c in dt_str if c.isnumeric()]) #grabs numeric values\n",
    "dt = pd.to_datetime(dt_str[:8]) #convert to datetime, grabs digits for dates only\n",
    "print(dt.date())\n",
    "time_var = pd.to_datetime(dt.date())\n",
    "ds['DATE'] = (time_var)\n",
    "ds = ds.assign_coords(time=ds.DATE)\n",
    "ds.close()\n",
    "# ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dims\n",
    "ds.Band1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = ds.std(dim='time')\n",
    "# print('this is sigma', sigma)\n",
    "\n",
    "# plt.plot(sigma)\n",
    "# plt.show()\n",
    "\n",
    "# d = ds.Band1.mean\n",
    "# # d = ds.mean(var=\"Band1\")\n",
    "# d\n",
    "# plt.plot(d())\n",
    "# plt.show()\n",
    "\n",
    "# varsn = ds.Band1.var(dim='time') #compute variance on every pixel in the time dimention \n",
    "# varsn = np.where(varsn>.001, varsn, np.nan) # filters everything greater than 1mm (i.e gives alpha bg)\n",
    "# fig = plt.figure(figsize=(15, 10))\n",
    "# plt.imshow(varsn[::-1,:], cmap='jet', vmin=.05, vmax=1.0) #[::-1,:] - reverses it\n",
    "# plt.title('snow depth [50m] variance, 2013-2016')\n",
    "# plt.colorbar()\n",
    "# plt.savefig('figs/var_13-16', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
