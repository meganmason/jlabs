{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_20m_path = '/Users/meganmason491/Documents/research/sierra/data/20m_analysis/terrain/tuolumne_msk_20m.asc'\n",
    "elv_20m_path = '/Users/meganmason491/Documents/research/sierra/data/20m_analysis/terrain/tuolumne_dem_20m.asc'\n",
    "asp_20m_path = '/Users/meganmason491/Documents/research/sierra/data/20m_analysis/terrain/tuolumne_asp_20m.asc'\n",
    "slp_20m_path = '/Users/meganmason491/Documents/research/sierra/data/20m_analysis/terrain/tuolumne_slp_20m.asc'\n",
    "\n",
    "dep_20m_path = '/Users/meganmason491/Documents/research/sierra/data/20m_analysis/ascii/20170129_SUPERsnow_depth_20m.asc' #just one depth image...\n",
    "years = list(range(2013, 2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open\n",
    "msk_ = np.loadtxt(msk_20m_path, skiprows=6)\n",
    "elv_ = np.loadtxt(elv_20m_path, skiprows=6)\n",
    "asp_ = np.loadtxt(asp_20m_path, skiprows=7) \n",
    "slp_ = np.loadtxt(slp_20m_path, skiprows=7) \n",
    "dep_ = np.loadtxt(dep_20m_path, skiprows=7) / 10                      #convert mm to cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten\n",
    "msk = msk_.flatten()\n",
    "elv = elv_.flatten()\n",
    "asp = asp_.flatten()\n",
    "slp = slp_.flatten()\n",
    "dep = dep_.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filters: (1) Tuolumne Basin, (2) Snow Covered Areas\n",
    "elv = elv[(msk==1) & (dep>0)]\n",
    "asp = asp[(msk==1) & (dep>0)]\n",
    "slp = slp[(msk==1) & (dep>0)] \n",
    "dep = dep[(msk==1) & (dep>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize snow depth values\n",
    "sdv = (dep - dep.mean()) / dep.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elv</th>\n",
       "      <th>asp</th>\n",
       "      <th>slp</th>\n",
       "      <th>SDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3173.589355</td>\n",
       "      <td>231.494385</td>\n",
       "      <td>2.798378</td>\n",
       "      <td>-0.700011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3174.205078</td>\n",
       "      <td>224.230560</td>\n",
       "      <td>2.318916</td>\n",
       "      <td>-1.313743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3174.610107</td>\n",
       "      <td>277.199219</td>\n",
       "      <td>0.770132</td>\n",
       "      <td>-0.575903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3172.035645</td>\n",
       "      <td>199.983109</td>\n",
       "      <td>3.083293</td>\n",
       "      <td>0.083235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3172.527100</td>\n",
       "      <td>218.970459</td>\n",
       "      <td>4.072806</td>\n",
       "      <td>-0.367794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           elv         asp       slp       SDV\n",
       "0  3173.589355  231.494385  2.798378 -0.700011\n",
       "1  3174.205078  224.230560  2.318916 -1.313743\n",
       "2  3174.610107  277.199219  0.770132 -0.575903\n",
       "3  3172.035645  199.983109  3.083293  0.083235\n",
       "4  3172.527100  218.970459  4.072806 -0.367794"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe\n",
    "d = {'elv': elv, 'asp': asp, 'slp': slp, 'SDV': sdv}                 #data to be put in df\n",
    "df_ = pd.DataFrame(d)                                                #create df\n",
    "df = df_.dropna()                                                    #remove all rows with any NaN's\n",
    "df.drop(df[df['asp'] < 0].index, inplace=True)                       #remove all -9999 in aspect values (i.e. the lakes, water bodies)\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #bin labels\n",
    "# bin_labels = {'0-50': 0, '51-75': 1, '76-100': 2, '101-125': 3, '126-150': 4, '151-200': 5, '200-250': 6, '250+': 7}\n",
    "\n",
    "#method 1\n",
    "#bin snow depth to categorical bins\n",
    "def bin_sd(x):\n",
    "    if 0 < x <= 50:\n",
    "        return 0\n",
    "    elif 50 < x <= 75:\n",
    "        return 1\n",
    "    elif 75 < x <= 100:\n",
    "        return 2\n",
    "    elif 100 < x <= 125:\n",
    "        return 3\n",
    "    elif 125 < x <= 150:\n",
    "        return 4\n",
    "    elif 150 < x <= 200:\n",
    "        return 5\n",
    "    elif 200 < x <= 250:\n",
    "        return 6\n",
    "    elif x >250:\n",
    "        return 7\n",
    "\n",
    "df['sd_bin'] = df['dep'].apply(bin_sd)\n",
    "# df['bin_labels'] = bin_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #give label names\n",
    "# labels = ['0-50', '51-75', '76-100', '101-125', '126-150', '151-200', '200-250', '251+']\n",
    "# # df['sd_labels'] = pd.cut(df['dep'], bins=[0, 50, 75, 100, 125, 150, 200, 250, float('Inf')], labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #drop snow depth....\n",
    "# df = df.drop(['dep'], axis=1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.float_format', lambda x: '%.2f' % x)           #float value to the hundredths place\n",
    "# df.describe()                                                         #summary stats, 50%=median, note Aspect and Slope mins=0, ~2.48 million values in remaining dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=df[['elv', 'asp', 'slp']] #features\n",
    "# y=df['sd_bin'] #values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "# clf=RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=clf.predict(X_test)\n",
    "# from sklearn import metrics\n",
    "# print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #feature importance\n",
    "# feature_imp = pd.Series(clf.feature_importances_, index=df.columns[:3]).sort_values(ascending=False)\n",
    "# feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating a bar plot\n",
    "# sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# # Add labels to your graph\n",
    "# plt.xlabel('Feature Importance Score')\n",
    "# plt.ylabel('Features')\n",
    "# plt.title(\"Visualizing Important Features\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN ALL FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "msk_20m_path = '/Users/meganmason491/Documents/research/sierra/data/20m_analysis/terrain/tuolumne_msk_20m.asc'\n",
    "elv_20m_path = '/Users/meganmason491/Documents/research/sierra/data/20m_analysis/terrain/tuolumne_dem_20m.asc'\n",
    "asp_20m_path = '/Users/meganmason491/Documents/research/sierra/data/20m_analysis/terrain/tuolumne_asp_20m.asc'\n",
    "slp_20m_path = '/Users/meganmason491/Documents/research/sierra/data/20m_analysis/terrain/tuolumne_slp_20m.asc'\n",
    "dep_20m_path = '/Users/meganmason491/Documents/research/sierra/data/20m_analysis/ascii/*.asc' \n",
    "years = list(range(2013, 2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle 'fixed' terrain layers\n",
    "\n",
    "#open\n",
    "msk_ = np.loadtxt(msk_20m_path, skiprows=6)\n",
    "elv_ = np.loadtxt(elv_20m_path, skiprows=6)\n",
    "asp_ = np.loadtxt(asp_20m_path, skiprows=7) \n",
    "slp_ = np.loadtxt(slp_20m_path, skiprows=7)\n",
    "\n",
    "#flatten\n",
    "msk = msk_.flatten()\n",
    "elv = elv_.flatten()\n",
    "asp = asp_.flatten()\n",
    "slp = slp_.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = glob.glob(dep_20m_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates = []\n",
    "\n",
    "# for f in sorted(flist):\n",
    "#     dt_str = f.split(\"/\")[-1] #splits on '/' and saves the last one\n",
    "#     dt_str = \"\".join([c for c in dt_str if c.isnumeric()]) #grabs numeric values for date info\n",
    "#     dates.append(dt_str[:-2]) #append to date list\n",
    "\n",
    "# # dates_dt = [datetime.strptime(date, '%Y%m%d') for date in dates]\n",
    "# dates = pd.to_datetime(dates, format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(f, msk, elv, asp, slp):\n",
    "    dep_ = np.loadtxt(f, skiprows=7) / 10                      #convert mm to cm\n",
    "    dep = dep_.flatten()\n",
    "    \n",
    "    #filters: (1) Tuolumne Basin, (2) Snow Covered Areas\n",
    "    elv = elv[(msk==1) & (dep>0)]\n",
    "    asp = asp[(msk==1) & (dep>0)]\n",
    "    slp = slp[(msk==1) & (dep>0)] \n",
    "    dep = dep[(msk==1) & (dep>0)]\n",
    "    \n",
    "    #dataframe\n",
    "    d = {'elv': elv, 'asp': asp, 'slp': slp, 'dep': dep}                 #data to be put in df\n",
    "    df_ = pd.DataFrame(d)                                                #create df\n",
    "    df = df_.dropna()                                                    #remove all rows with any NaN's\n",
    "    df.drop(df[df['asp'] < 0].index, inplace=True)                       #remove all -9999 in aspect values (i.e. the lakes, water bodies)\n",
    "    \n",
    "    return df\n",
    " \n",
    "def bin_sd(x):\n",
    "    if 0 < x <= 50:\n",
    "        return 0\n",
    "    elif 50 < x <= 75:\n",
    "        return 1\n",
    "    elif 75 < x <= 100:\n",
    "        return 2\n",
    "    elif 100 < x <= 125:\n",
    "        return 3\n",
    "    elif 125 < x <= 150:\n",
    "        return 4\n",
    "    elif 150 < x <= 200:\n",
    "        return 5\n",
    "    elif 200 < x <= 250:\n",
    "        return 6\n",
    "    elif x >250:\n",
    "        return 7\n",
    "    \n",
    "def rfc(df):\n",
    "    \n",
    "    X=df[['elv', 'asp', 'slp']] #features\n",
    "    y=df['sd_bin'] #values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) #train/test split\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred=clf.predict(X_test)\n",
    "\n",
    "    acc = round(metrics.accuracy_score(y_test, y_pred) * 100) #accuracy \n",
    "    \n",
    "    \n",
    "    feature_imp = pd.Series(clf.feature_importances_, index=df.columns[:3]).sort_values(ascending=False) #feature importance\n",
    "\n",
    "    featImp_elv = round(feature_imp['elv'] * 100)\n",
    "    featImp_asp = round(feature_imp['asp'] * 100)\n",
    "    featImp_slp = round(feature_imp['slp'] * 100)\n",
    "    \n",
    "    return acc, featImp_elv, featImp_asp, featImp_slp\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "accs = []\n",
    "featImp_elvs = []\n",
    "featImp_asps = []\n",
    "featImp_slps = []\n",
    "\n",
    "for i, f in enumerate(sorted(flist)): \n",
    "    \n",
    "    print('processing file {}:'.format(i), f.split('/')[-1])\n",
    "    \n",
    "    dt_str = f.split(\"/\")[-1] #splits on '/' and saves the last one\n",
    "    dt_str = \"\".join([c for c in dt_str if c.isnumeric()]) #grabs numeric values for date info\n",
    "    dates.append(dt_str[:-2]) #append to date list\n",
    "    \n",
    "    df = prep_data(f, msk, elv, asp, slp)\n",
    "    \n",
    "    df['sd_bin'] = df['dep'].apply(bin_sd)\n",
    "    \n",
    "    df = df.drop(['dep'], axis=1)\n",
    "    \n",
    "    acc, featImp_elv, featImp_asp, featImp_slp = rfc(df)\n",
    "    \n",
    "    accs.append(acc)    \n",
    "    featImp_elvs.append(featImp_elv)\n",
    "    featImp_asps.append(featImp_asp)\n",
    "    featImp_slps.append(featImp_slp)\n",
    "    print('~~round complete~~')\n",
    "    \n",
    "dates = pd.to_datetime(dates, format='%Y%m%d')\n",
    "\n",
    "print('COMPLETE!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(list(zip(pd.to_datetime(dates), accs, featImp_elvs, featImp_asps, featImp_slps)),\n",
    "                        columns = ['Date', 'RFC Accuracy (%)', 'Elevation Importance (%)', 'Aspect Importance (%)', 'Slope Importance (%)'])\n",
    "dataframe\n",
    "dataframe.to_csv('/Users/meganmason491/Documents/research/sierra/analysis/results/tmp/SDV_featureImportance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lst = ['a', 'b', 'c']\n",
    "# lst2 = ['ff', 'gg', 'hh']\n",
    "# r = pd.DataFrame(list(zip(lst, lst2)), \n",
    "#                columns =['Name', 'val']) \n",
    "# r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST example of Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=pd.DataFrame({\n",
    "#     'sepal length':iris.data[:,0],\n",
    "#     'sepal width':iris.data[:,1],\n",
    "#     'petal length':iris.data[:,2],\n",
    "#     'petal width':iris.data[:,3],\n",
    "#     'species':iris.target\n",
    "# })\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=data[['sepal length', 'sepal width', 'petal length', 'petal width']]\n",
    "# y=data['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #feature importance\n",
    "# clf = RandomForestClassifier(n_estimators=100)\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_imp= pd.Series(clf.feature_importances_, index=iris.feature_names).sort_values(ascending=False)\n",
    "# feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating a bar plot\n",
    "# sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# # Add labels to your graph\n",
    "# plt.xlabel('Feature Importance Score')\n",
    "# plt.ylabel('Features')\n",
    "# plt.title(\"Visualizing Important Features\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
